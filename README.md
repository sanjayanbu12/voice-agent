ğŸ“˜ Sanjay Bot â€” RAG Voice Assistant

FastAPI + Weaviate Vector DB + Gemini 2.0 Flash + React + Vite

An intelligent voice-enabled chatbot that answers questions ONLY from user-uploaded documents (PDF/DOCX/TXT).
It uses a RAG (Retrieval-Augmented Generation) pipeline with Weaviate + Gemini 2.0.

âœ¨ Features

ğŸ“„ Upload PDF / DOCX / TXT

ğŸ” Extracts text + Chunks + Embeds (Gemini text-embedding-004)

ğŸ§  Stores vectors inside Weaviate Cloud

ğŸ¤– Queries Gemini 2.0 Flash using ONLY retrieved chunks

ğŸ¤ Voice input & voice output

ğŸ” Reset system to delete all documents

âš¡ FastAPI backend + React frontend

ğŸ’¬ Chat UI + RAG pipeline


âš™ï¸ Setup Instructions

ğŸ§© 1. Backend Setup (FastAPI)
Install dependencies:
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

ğŸŸ¦ 2. Create .env inside backend/
GEMINI_API_KEY="your_gemini_key"

WEAVIATE_URL="https://your-cluster.weaviate.network"
WEAVIATE_API_KEY="your_weaviate_key"

API_HOST=0.0.0.0
API_PORT=8000

â–¶ï¸ 3. Start Backend
uvicorn app.main:app --reload


Backend runs at:

ğŸ‘‰ http://localhost:8000

ğŸŸ© 4. Frontend Setup (React + Vite)
cd frontend
npm install

Create frontend/.env:
VITE_API_BASE_URL="http://localhost:8000"

Start frontend
npm run dev


Frontend runs at:

ğŸ‘‰ http://localhost:5173

ğŸ§  RAG Pipeline Explained
1. User uploads PDF/DOCX/TXT

â†’ Backend extracts text

2. chunk_text()

â†’ Splits into overlapping chunks

3. embed_text()

â†’ Uses Gemini model: text-embedding-004

4. store_document()

â†’ Saves chunks + vectors into Weaviate

5. User asks a question

â†’ retrieve_similar(query) performs vector search

6. Gemini 2.0 Flash

â†’ Answers using ONLY retrieved chunks
â†’ If answer not found â†’ returns fallback:

"I don't have enough information to answer this from the uploaded document."

ğŸ” Reset System

The reset button:

Deletes all vectors from Weaviate

Deletes uploads folder

Recreates schema

Clears UI